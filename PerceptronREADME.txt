README1. Unigram.py Ð contains the unigram representation of the text data. Perceptron is trained and run on this representation.Used Countvectorizer() function from scikit learn to count the term frequency.2. Bigram.py Ð contains the bigram representation of the text data. Perceptron is trained and run on this representation.Used Countvectorizer() function from scikit learn to count the biigram term frequency.3. Trigram.py Ð contains the trigram representation, which is our chosen fourth representation of the text data. Perceptron is trained and run on this representation.Used Countvectorizer() function from scikit learn to count the trigram term frequency.4. Tf-idf.py Ð contains the tf-idf representation of the text data. Perceptron is trained and run on this representation. Used Countvectorizer() function from scikit learn to count the term frequency. And then computed the inverse document frequency using math log10 function. Used this idf vector on both the train and the test data to get the respective features.